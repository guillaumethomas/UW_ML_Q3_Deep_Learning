{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# TensorFlow Convolutional Neural Network for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Imports \n",
    "Here, we import keras, the model we are going to use (a sequential model), three different types of layers namely convolution layer, max-pooling layer and dense layers. We will also import activation functions and flattening operation from the layers module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### TODO import keras related libraries here\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Flatten, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Load Data\n",
    "There is a lot to building a succesful model. Loading datasets, formatting them, presenting them to the model in batches are all part of a successul machine learning algorithm. Here we show how the specific data we are using is loaded, and formatted in the Keras library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [CIFAR 10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    " - [KERAS CIFAR 10](https://keras.io/examples/cifar10_cnn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets.cifar import load_batch\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Loads CIFAR10 dataset.\n",
    "    # Returns\n",
    "        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "    \"\"\"\n",
    "    path = './cifar-10-batches-py'\n",
    "\n",
    "    num_train_samples = 50000\n",
    "\n",
    "    x_train = np.empty((num_train_samples, 3, 32, 32), dtype='uint8')\n",
    "    y_train = np.empty((num_train_samples,), dtype='uint8')\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        fpath = os.path.join(path, 'data_batch_' + str(i))\n",
    "        (x_train[(i - 1) * 10000: i * 10000, :, :, :],\n",
    "         y_train[(i - 1) * 10000: i * 10000]) = load_batch(fpath)\n",
    "\n",
    "    fpath = os.path.join(path, 'test_batch')\n",
    "    x_test, y_test = load_batch(fpath)\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        x_train = x_train.transpose(0, 2, 3, 1)\n",
    "        x_test = x_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exploring the dataset\n",
    "First we need to figure out our image size and number of categories(or classes) we are trying model. Fill in the following parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def params():\n",
    "    num_classes = 10\n",
    "    in_shape = (32,32)\n",
    "    batch_size = 32\n",
    "    epochs = 10\n",
    "    return [num_classes, in_shape, batch_size, epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "[num_classes, in_shape, batch_size, epochs] = params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Building the Model \n",
    "Here you are going to build the CNN model. Provide the implementation for ConvConvMaxpoolDropout followed by ConvConvMaxpoolDropout and a classification module of DenseDropDense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(in_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 1.7947 - acc: 0.3410 - val_loss: 1.5163 - val_acc: 0.4521\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 1.4860 - acc: 0.4619 - val_loss: 1.3250 - val_acc: 0.5291\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 99s 2ms/step - loss: 1.3441 - acc: 0.5191 - val_loss: 1.2415 - val_acc: 0.5528\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 99s 2ms/step - loss: 1.2442 - acc: 0.5576 - val_loss: 1.1345 - val_acc: 0.6024\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 99s 2ms/step - loss: 1.1606 - acc: 0.5902 - val_loss: 1.0640 - val_acc: 0.6319\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 1.0907 - acc: 0.6166 - val_loss: 0.9925 - val_acc: 0.6521\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 151s 3ms/step - loss: 1.0384 - acc: 0.6357 - val_loss: 0.9796 - val_acc: 0.6576\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 119s 2ms/step - loss: 0.9897 - acc: 0.6530 - val_loss: 0.9424 - val_acc: 0.6670\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 99s 2ms/step - loss: 0.9529 - acc: 0.6663 - val_loss: 0.8804 - val_acc: 0.6918\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 99s 2ms/step - loss: 0.9169 - acc: 0.6808 - val_loss: 0.8626 - val_acc: 0.7001\n"
     ]
    }
   ],
   "source": [
    "# Putting everything together. Build your model, initiate RMSprop optimizer, and compile it with categorical_crossentropy.  \n",
    "def train_cifar():\n",
    "    \n",
    "    model = build_model(2)\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "    return model\n",
    "\n",
    "model = train_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fc06f349ba8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /home/ccc_v1_w_92a51_13695/asn46667_4/asn46668_1/work/saved_models/keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 5s 520us/step\n",
      "Test loss: 0.8626131256103515\n",
      "Test accuracy: 0.7001\n"
     ]
    }
   ],
   "source": [
    "model = a\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
